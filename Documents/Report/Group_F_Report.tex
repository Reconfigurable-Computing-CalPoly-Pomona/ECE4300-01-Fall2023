\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{ECE 4300 Group F Project\\
Scalability of YOLOv5 and Tensorflow Lite\\
{\footnotesize \textsuperscript{}}
\thanks{}
}

\author{Matthew West, Bryant Ta, Rojelio Hinojosa, Davit Avetisyan, Mohamed El-Hadedy\\(mjwest,bzta,rogelioh,ddavetisyan,mealy)@cpp.edu\\
ECE Department, College of Engineering\\
\textit{California Polytechnic State University, Pomona}}

\maketitle

\begin{abstract}
Advancements in technology have undeniably ushered in a remarkable era of progress, particularly in the realm of object detection within computer systems. This transformative development hinges on the deployment of diverse models with cutting-edge algorithms that meticulously arrange to identify specific objects in images. Delving into the intricacies of this paper, the focus is on unraveling the nuances embedded in the YOLO (You Only Look Once) and TensorFlow Lite models, both serving as exemplars of sophisticated methodologies in object detection. Ensuring the seamless functioning of these models necessitates the exploration and implementation of innovative techniques and methodologies. Addressing inherent challenges becomes not just important but critical to maximizing the efficiency of these models. A comprehensive analysis delves into the layers of confidence levels and image precision, unraveling valuable insights that contribute to the generation of unique information. Navigating through the labyrinth of challenges associated with data processing, the accuracy in identifying specific objects becomes a focal point, raising intriguing questions about the viability of datasets. Object detection, as exemplified by the YOLO and TensorFlow Lite models, is not merely a technological feat but a journey toward future endeavors of colossal significance. Embracing the evolution of technology, these advancements hold the promise of revolutionizing industries and offering innovative solutions that seamlessly integrate into daily tasks. This paper not only captures the current landscape of object detection but also sets the stage for comprehending the expansive power these technologies wield across diverse sectors.   
\end{abstract}

\begin{IEEEkeywords}
Analysis,Code,Data,TensorFlow Lite,YOLO
\end{IEEEkeywords}

\section{Introduction}
Object detection is a big part of computer vision and revolutionizes the way machines understand visual data.\cite{Kanjee_2023} Typically, for video analysis and precise image processing, industries all over the world use these models to ensure safety in their workplaces or cars.\cite{Gallagher_2023} The clear processing of objects in an image supports AI systems which are all put to use in several high-tech models.   

\section{History and Use}
\subsection{YOLO Model}
The YOLO model stands for You Only Look Once. There are about 14 versions of the model to this date, with the YOLOv8 being the latest. YOLO works by dividing an image into a grid and predicts the bounding boxes with confidence scores or accuracy for each object in the image.\cite{Sahota_2023} Each YOLO version was better than its predecessor by how much faster and more efficient it is in detecting objects with great accuracy. The various versions of the YOLO model contain many unique or complex architectures to assist in object detection, such as a CNN architecture called DarkNet-53 in YOLOv3, CSPNet in YOLOv4, EfficientDet in YOLOv5, and many more.  

\subsection{TensorFlow Lite}
TensorFlow Lite is an open-source learning framework designed for on-device inference. It provides a set of tools that enables developers to run their models on IoT devices.\cite{Boesch_2021} TensorFlow Lite is a lighter version of TensorFlow and is mainly for mobile edge devices with the ability to analyze or predict any models that are already made. TensorFlow Lite has many advantages, such as model conversion, where models can transfer directly to the Lite version of the original. In addition, there is minimal latency, it's user-friendly, and edge inference doesn't require an internet connection.    


\section{Dataset}
\subsection{Images}
Achieving a robust dataset is contingent upon curating a diverse array of images. The objective is to procure visuals that encompass the targeted objects within natural settings. Emphasis is placed on sourcing images depicting commonplace instances of these objects. For instance, in the case of detecting raw wood material, images featuring trees are imperative, while those showcasing unique wooden artifacts, such as a distinct wooden car, are considered less pertinent. Despite the educational value inherent in the latter, it diverges from the typical visual landscape found in common suburban and urban environments.

Furthermore, dataset acquisition involves a meticulous selection process, incorporating images displaying the objects from various perspectives. To adhere to the dataset structure, each class, encompassing wood, concrete, glass, metal, and plastic, is represented by a curated set of one hundred images. This approach is a strategic compromise, acknowledging the constraint of time that limited our image collection capacity. Consequently, the focus has been on identifying a judicious selection of objects that authentically encapsulate the essence of the raw materials under consideration, while adhering to the imposed limit of one hundred images per class.
\subsection{Annotation and Preparation}
Following the acquisition of the images, they were systematically organized into a compressed file format, which was subsequently uploaded to a designated annotation software. For YOLOv5, Roboflow was employed, while TensorFlow Lite utilizes LabelImg in the workflow. It is noteworthy that Roboflow can be utilized for annotating images intended for TensorFlow Lite, although a conversion software available on Roboflow's platform is required to ensure proper image formatting.

Irrespective of the software chosen, the annotation process adheres to a standardized procedure. Image by image, bounding boxes were meticulously applied to encapsulate the targeted objects, specifying the relevant class corresponding to each boxâ€”a class representing one of the raw materials under consideration. Upon completing the annotation of all images, the dataset can be exported. Both Roboflow and LabelImg generate essential .txt files for YOLOv5 and .xml files for TensorFlow Lite, preserving the annotation data for each image.

Prior to initiating the training phase, a crucial step involves categorizing the images into three distinct groups. The "Train" category is utilized for the actual training of the models, while "Validate" serves as a means to assess the model's performance during training. An optional "Test" category is reserved for a final evaluation of accuracy and overall performance post-training. The "Train" and "Validate" sets are employed concurrently throughout the training process, while the "Test" images are exclusively utilized post-training.

With these preparations complete, the datasets are primed for model training. Notably, augmentations were applied to enhance the dataset's robustness, encompassing techniques such as vertical or horizontal mirroring and subtle image modifications. Despite the suboptimal nature of these augmentations, necessitated by time and resource constraints, they prove instrumental in refining the accuracy and efficacy of the object detection models.

\section{Issues}
\subsection{Dataset Issues}
Training object detection models on images of wood, concrete, glass, metal, and plastic presents unique challenges for each material. Wood, characterized by consistent texture and color, poses relatively minimal issues during training. In contrast, concrete exhibits diverse forms in natural settings, including roads, stairs, statues, walls, and tables, rendering training, especially for TensorFlow Lite, intricate. The transparency and reflective nature of glass introduce complexities, as the model grapples with distinguishing the glass itself from its surroundings, including objects reflected in or behind it. Metal, with its varied compositions and reflective properties, complicates the establishment of a unified approach for both YOLOv5 and TensorFlow Lite. The diverse array of plastic compounds poses a significant challenge for YOLOv5, given the substantial variations in shape, size, and color. These material-specific challenges are compounded by issues arising from image similarities between classes, necessitating a nuanced approach to training to ensure accurate and robust object detection across the entire spectrum of materials. To enhance the models in the future, a substantial increase in the quantity of images and improved diversity is imperative. A proposition of targeting approximately 1000 images for the wood class, around 1500 for concrete and glass, and approximately 2000 for metal and plastic, aligning with the confidence levels.

\section{Demo and Analysis}
\subsection{YOLO Demo}
Training the three selected models on the custom dataset allows for benchmarks to be performed with respect to confidence levels. The three models selected for training are the YOLOv5n, YOLOv5s, and YOLOv5m models. The larger two sizes consisting of YOLOv5l and YOLOv5x are not trained as they require far more video memory than the system contained. Training each model for 1,000 epochs allows for any inadequacies in the dataset to be mostly compensated for. After 50 minutes the YOLOv5n model is done training with the YOLOv5s and YOLOv5m models finishing training after 1.9 and 2.7 hours respectively. The overall and material specific mAP values are detailed in Table 1.\\
\begin{table}
        \centering
        \begin{tabular}{lrrr}
            Model & YOLOv5n & YOLOv5s & YOLOv5m\\
            Time to Train & 50 Minutes & 1.95 Hours & 2.7 Hours\\
            Overall mAP & .35 & .37 & .40\\
            Wood mAP & .70 & .75 & .80\\
            Concrete mAP & .35 & .37 & .40\\
            Glass mAP & .34 & .37 & .40\\
            Metal mAP & .17 & .19 & .20\\
            Plastic mAP & .17 & .19 & .20\\
            Average FPS & 322 & 232 & 120\\
            Maximum Streams & 16 & 13 & 8\\
            FPS at Max Streams & 45 & 30 & 20\\
        \end{tabular}
        \caption{Model Training and Performance Statistics}
        \label{tab:Performance}
    \end{table}
Testing indicates that the models have the highest confidence levels when identifying wooden materials. This is likely due to the relatively unique form and appearance that wood takes in comparison to the other materials.\\
Testing concurrent video streams on an x86 machine is done in order to identify the cost per video stream. Testing reveals that the x86 system tested can process 8, 13, or 16 concurrent video streams when utilizing YOLOv5m, YOLOv5s, and YOLOv5n respectively. 

\subsection{TensorFlow Lite Demo}

TensorFlow Lite Performance:\\
Calculated mAP at 0.50 IoU Threshold\\
0.708 = Plastic\\
0.604 = Glass\\
0. 682= Wood\\
0.589 = Metal\\ 
0. 302 = Concrete\\

TensorFlow Lite is used in this project because it is designed for low-powered devices making the implementation achievable in five easy steps. These steps include updating Raspberry Pi's OS, downloading the GitHub repository, creating a virtual environment, installing TensorFlow Lite, and running the program using python3. Secondly, TensorFlow Lite doesn't require the installation of Torch vision which is very problematic trying to install it on a 32-bit Raspberry Pi 3. This project uses the GitHub repository from EdjeElectronics. The best performance type for the Raspberry Pi 3 requires less precision due to the fact that it is a smaller model, specifically a 32-bit OS. An advantage of using a smaller model on this project in order to run TensorFlow Lite is avoiding constant OS shutdowns caused by overheating the Raspberry Pi device. To get better accuracy readings the number of threads would have to increase, altering the performance by using more resources and power consumption.

\section{Conclusion}
In conclusion, object detection holds immense potential in the future for its ability to produce quality and precise image processing that could revolutionize technology forever. With faster, more accurate, and more robust improvements, the development of more object detection models will grow. Object detection could contribute massively to the evolution of self-driving cars, smart cities, and intelligence surveillance systems.\cite{Kanjee_2023} The importance of such a topic makes learning and researching the possibilities of object detection extraordinary.    
 
\section*{Acknowledgment}

The authors would like to thank Dr.Aly for allowing us to research and be exposed to the topic of YOLO models and their uses for object detection. 

%references section here
%look at sources.bib to find out how to do references
%to cite do \cite{author's last name in sources}
\cite{Jocher_2023}
\cite{Arie_2022}
\cite{Lee_2021}
\bibliographystyle{IEEEtran}
\bibliography{sources}
\end{document}
